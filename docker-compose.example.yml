# ABS-KoSync Enhanced - Example Docker Compose Configuration
#
# Copy this file to docker-compose.yml and fill in your values.
# See README.md for detailed configuration instructions.

services:
  abs-kosync:
    image: ghcr.io/cporcellijr/abs-kosync-bridge:latest

    # Optional: Build locally if you need specific modifications or GPU libraries included
    # build:
    #   context: .
    #   args:
    #     # Set to "true" to download NVIDIA CUDA libraries (adds ~800MB to image)
    #     INSTALL_GPU: "false"
    container_name: abs_kosync
    restart: unless-stopped

    environment:
      # ============================================
      # General Settings
      - TZ=America/New_York
      - LOG_LEVEL=INFO
      # - KOSYNC_PORT=5758 # Enable Split-Port Mode (Safe for Internet Exposure)

      # === OPTIONAL: Initial Configuration ===
      # It is recommended to configure these in the Web UI, but you can bootstrap them here.

      # Audiobookshelf
      # - ABS_SERVER=http://your-abs-server:13378
      # - ABS_TOKEN=your-api-token
      # - ABS_ONLY_SEARCH_IN_ABS_LIBRARY_ID=false # Set to true to restrict search to one library

      # Integrations
      # - KOSYNC_URL=https://koreader.example.com
      # - BOOKLORE_URL=http://booklore.example.com
      # - STORYTELLER_URL=http://storyteller.example.com

      # CWA (Calibre-Web Automated) - For syncing ebooks without local files
      # - CWA_ENABLED=true
      # - CWA_SERVER=http://calibre-web.example.com/opds
      # - CWA_USERNAME=user
      # - CWA_PASSWORD=pass

    volumes:
      # === REQUIRED ===
      - ./data:/data                    # App data (database, cache)
      - /path/to/ebooks:/books          # Your EPUB library (Required unless using CWA/Booklore exclusively)

      # === OPTIONAL: Forge (Storyteller) ===
      - /path/to/storyteller/library:/storyteller_library

    ports:
      - "8080:5757"   # Admin Dashboard (Keep Internal/LAN)
      # - "5758:5758" # Sync Protocol (Enable if KOSync Port is set)

    networks:
      - your-network
    # ============================================
    # GPU SUPPORT (OPTIONAL)
    # ============================================
    # Uncomment below to enable NVIDIA GPU acceleration for Whisper.
    # Requires: docker with nvidia-container-toolkit installed.
    # See: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
    #
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

networks:
  your-network:
    external: true
